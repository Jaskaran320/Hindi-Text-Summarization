{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T16:59:50.326169Z","iopub.status.busy":"2024-04-25T16:59:50.325526Z","iopub.status.idle":"2024-04-25T17:00:06.123919Z","shell.execute_reply":"2024-04-25T17:00:06.122691Z","shell.execute_reply.started":"2024-04-25T16:59:50.326136Z"},"trusted":true},"outputs":[],"source":["!pip install -q rouge_score bert_score"]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-25T17:00:06.126239Z","iopub.status.busy":"2024-04-25T17:00:06.125945Z","iopub.status.idle":"2024-04-25T17:00:06.195613Z","shell.execute_reply":"2024-04-25T17:00:06.194942Z","shell.execute_reply.started":"2024-04-25T17:00:06.126211Z"},"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, TrainingArguments, pipeline\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from datasets import load_metric, Dataset\n","from tqdm import tqdm\n","from bert_score import score\n","import wandb"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T17:00:06.196991Z","iopub.status.busy":"2024-04-25T17:00:06.196660Z","iopub.status.idle":"2024-04-25T17:01:09.553058Z","shell.execute_reply":"2024-04-25T17:01:09.552030Z","shell.execute_reply.started":"2024-04-25T17:00:06.196960Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2696bb101b544db8eb4e7614f668a41","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1b855588c48c4535bc208e7b1fab3848","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/832 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"76b4e3554d924b0cb1a34fbebf6bf88e","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/1.90M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6eb542b2834f46d0aa4653b078b72430","version_major":2,"version_minor":0},"text/plain":["added_tokens.json:   0%|          | 0.00/221 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1796478f11284350b4fbfe062da03ee0","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/398 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0dc749a4f78b4839965eeab99e25470a","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/976M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n","  return self.fget.__get__(instance, owner)()\n"]}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\").to('cuda')\n","target = \"Summary\""]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T17:01:09.555650Z","iopub.status.busy":"2024-04-25T17:01:09.555358Z","iopub.status.idle":"2024-04-25T17:01:13.252306Z","shell.execute_reply":"2024-04-25T17:01:13.251552Z","shell.execute_reply.started":"2024-04-25T17:01:09.555625Z"},"trusted":true},"outputs":[],"source":["train_data = pd.read_csv(\"/kaggle/input/hindi-dataset/hindi_train.csv\")\n","# train_data.drop(columns=[\"Summary\"], inplace=True)\n","\n","# test_data = pd.read_csv(\"/kaggle/input/hindi-dataset/HindiNews_test.csv\")\n","# test_data.rename(columns={\"id\": \"Id\"}, inplace=True)\n","# data = pd.concat([train_data, test_data], axis=0)\n","data = train_data\n","\n","train_dataset, test_dataset = train_test_split(data, test_size=0.1, shuffle=False)\n","train_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, shuffle=False)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T17:01:13.253577Z","iopub.status.busy":"2024-04-25T17:01:13.253292Z","iopub.status.idle":"2024-04-25T17:03:24.116049Z","shell.execute_reply":"2024-04-25T17:03:24.115119Z","shell.execute_reply.started":"2024-04-25T17:01:13.253553Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d1c8660e1da64c83a1921f7fe63e95e2","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/17191 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b6a25c2654d84aa784cb11f5eef51b1b","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1911 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6399eb51f5e04db181df41a74c0cea43","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/2123 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["def preprocess_data(example):\n","    inputs = tokenizer(example[\"Article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to('cuda')\n","    outputs = tokenizer(example[target], padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\").to('cuda')\n","    return {\"input_ids\": inputs[\"input_ids\"].tolist(), \"attention_mask\": inputs[\"attention_mask\"].tolist(), \"labels\": outputs[\"input_ids\"].tolist()}\n","\n","train_dataset = Dataset.from_pandas(train_dataset)\n","train_dataset = train_dataset.map(preprocess_data, batched=True, batch_size=96)\n","val_dataset = Dataset.from_pandas(val_dataset)\n","val_dataset = val_dataset.map(preprocess_data, batched=True, batch_size=96)\n","test_dataset = Dataset.from_pandas(test_dataset)\n","test_dataset = test_dataset.map(preprocess_data, batched=True, batch_size=96)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T17:08:59.735620Z","iopub.status.busy":"2024-04-25T17:08:59.735261Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1374' max='4298' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1374/4298 11:53 < 25:21, 1.92 it/s, Epoch 0.64/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>2.313300</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>1.348500</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n","Non-default generation parameters: {'forced_eos_token_id': 2}\n"]}],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"/kaggle/working/model\",\n","    num_train_epochs=1,\n","    logging_dir=\"/kaggle/working/logs\",\n","    logging_steps=500,\n","    overwrite_output_dir=True,\n","    save_steps=1000,\n","    eval_steps=500,\n","    save_total_limit=3,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n",")\n","\n","trainer.train()\n","model.save_pretrained(\"/kaggle/working/finetuned_model\")\n","tokenizer.save_pretrained(\"/kaggle/working/finetuned_model\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/finetuned_model\").to('cuda')\n","tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/finetuned_model\", do_lower_case=False, use_fast=False, keep_accents=True)\n","\n","def generate_heading(article):\n","    inputs = tokenizer(article, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to('cuda')\n","    output = model.generate(inputs[\"input_ids\"], max_length=100, num_beams=4, early_stopping=True)\n","    return tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","predictions = [generate_heading(article) for article in tqdm(test_dataset[\"Article\"])]\n","\n","metric_rouge = load_metric(\"rouge\")\n","references = test_dataset[target]\n","rouge_scores = metric_rouge.compute(predictions=predictions, references=references)\n","\n","P, R, F1 = score(predictions, references, lang='hi', verbose=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with open(\"rouge_scores.txt\", \"w\") as f:\n","    f.write(str(rouge_scores))\n","\n","with open(\"bert_scores.txt\", \"w\") as f:\n","    f.write(f\"P: {P.mean()}\\nR: {R.mean()}\\nF1: {F1.mean()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rouge_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(P.mean())\n","print(R.mean())\n","print(F1.mean())"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!zip -r file.zip /kaggle/working/finetuned_model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from IPython.display import FileLink\n","FileLink(r'file.zip')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:08:55.603737Z","iopub.status.idle":"2024-04-25T17:08:55.604094Z","shell.execute_reply":"2024-04-25T17:08:55.603932Z","shell.execute_reply.started":"2024-04-25T17:08:55.603919Z"},"trusted":true},"outputs":[],"source":["# model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/finetuned_model\").to('cuda')\n","# tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/finetuned_model\", do_lower_case=False, use_fast=False, keep_accents=True)\n","\n","# def generate_heading(article):\n","#     inputs = tokenizer(article, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to('cuda')\n","#     output = model.generate(inputs[\"input_ids\"], max_length=64, num_beams=4, early_stopping=True)\n","#     return tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","# predictions = [generate_heading(article) for article in test_dataset[\"Article\"][:1]]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-04-25T17:08:55.605683Z","iopub.status.idle":"2024-04-25T17:08:55.606062Z","shell.execute_reply":"2024-04-25T17:08:55.605904Z","shell.execute_reply.started":"2024-04-25T17:08:55.605889Z"},"trusted":true},"outputs":[],"source":["# tokenizer = AutoTokenizer.from_pretrained(\"Someman/bart-hindi\", do_lower_case=False, use_fast=False, keep_accents=True)\n","# model = AutoModelForSeq2SeqLM.from_pretrained(\"Someman/bart-hindi\").to('cuda')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4871196,"sourceId":8217908,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
