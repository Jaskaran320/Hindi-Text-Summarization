{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!pip install -q rouge_score bert_score\n","!pip install evaluate"]},{"cell_type":"code","execution_count":43,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-25T16:20:32.295067Z","iopub.status.busy":"2024-04-25T16:20:32.294109Z","iopub.status.idle":"2024-04-25T16:20:32.303829Z","shell.execute_reply":"2024-04-25T16:20:32.302565Z","shell.execute_reply.started":"2024-04-25T16:20:32.295032Z"},"trusted":true},"outputs":[],"source":["from transformers import MBartForConditionalGeneration, AutoModelForSeq2SeqLM\n","from transformers import AlbertTokenizer, AutoTokenizer\n","import pickle as pkl\n","import pandas as pd\n","import numpy as np\n","from datasets import Dataset\n","import torch\n","from transformers import DataCollatorForSeq2Seq\n","from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","import evaluate\n","from tqdm.notebook import tqdm\n","from bert_score import score\n","from datasets import load_metric\n","import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wandb.login(key = \"788dd34f5b4737da2945fd15125f904c0649fb24\")"]},{"cell_type":"markdown","metadata":{},"source":["# Data Analysis"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["similarity = pkl.load(open(\"/kaggle/input/hindidataset/similarities.pkl\",\"rb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"/kaggle/input/hindidataset/HindiNews/HindiNews_train_v2/hindi_train.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.iloc[1][\"Article\"].split(\"।\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df.iloc[1][\"Heading\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["torch.nn.functional.softmax(input = torch.tensor(similarity[1]), dim = 0)"]},{"cell_type":"markdown","metadata":{},"source":["# Setting up the Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBARTSS\", do_lower_case=False, use_fast=False, keep_accents=True)\n","checkpoint = \"ai4bharat/IndicBARTSS\""]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"/kaggle/input/hindidataset/HindiNews/HindiNews_train_v2/hindi_train.csv\")\n","train_dataset = Dataset.from_pandas(train_df)\n","train_dataset = train_dataset.remove_columns([\"Id\"])\n","\n","test_df = pd.read_csv(\"/kaggle/input/hindidataset/HindiNews/HindiNews_test.csv\")\n","test_dataset = Dataset.from_pandas(test_df)\n","test_dataset = test_dataset.remove_columns([\"id\"])"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T16:45:00.654829Z","iopub.status.busy":"2024-04-25T16:45:00.653769Z","iopub.status.idle":"2024-04-25T16:45:00.679012Z","shell.execute_reply":"2024-04-25T16:45:00.677919Z","shell.execute_reply.started":"2024-04-25T16:45:00.654791Z"},"trusted":true},"outputs":[],"source":["dataset = train_dataset.train_test_split(test_size=0.3, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def preprocess_data(example):\n","    inputs = tokenizer(example[\"Article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n","    outputs = tokenizer(example[\"Summary\"], padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\")\n","    return {\"input_ids\": inputs[\"input_ids\"].tolist(), \"attention_mask\": inputs[\"attention_mask\"].tolist(), \"labels\": outputs[\"input_ids\"].tolist()}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batched_dataset = dataset.map(preprocess_data, batched = True, batch_size = 16)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batched_dataset"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation Metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["rouge = evaluate.load(\"rouge\")\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n","    result[\"gen_len\"] = np.mean(prediction_lens)\n","\n","    return {k: round(v, 4) for k, v in result.items()}"]},{"cell_type":"markdown","metadata":{},"source":["# Training"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["seq2seq_model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"/kaggle/working/model\",\n","    num_train_epochs=1,\n","    logging_dir=\"/kaggle/working/logs\",\n","    logging_steps=500,\n","    overwrite_output_dir=True,\n","    save_steps=1000,\n","    eval_steps=500,\n","    save_total_limit=3,\n",")\n","\n","trainer = Seq2SeqTrainer(\n","    model=seq2seq_model,\n","    args=training_args,\n","    train_dataset=batched_dataset[\"train\"],\n","    \n","    eval_dataset=batched_dataset[\"test\"],\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()\n","seq2seq_model.save_pretrained(\"/kaggle/working/finetuned_summary_model\")\n","tokenizer.save_pretrained(\"/kaggle/working/finetuned_summary_model\")"]},{"cell_type":"code","execution_count":44,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_34/2892384277.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  metric_rouge = load_metric(\"rouge\")\n","/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n","You can avoid this message in future by passing the argument `trust_remote_code=True`.\n","Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"21f0a0e3e40842ebb23ab907ad7b47ed","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9cb1ed68fbcc4c398525e7f1df304c28","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0661888d838a49679e6c534a03abfb6f","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a34059a8aee40ce8783a0c9595dc3c5","version_major":2,"version_minor":0},"text/plain":["vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"176b00957d864fa2ab9c4b60a7029f72","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04635b04c5064187a006a0edf743d81a","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4ba66ac026b4adbb6c411c723337dab","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9dbb8961c9e744719b1a5109a23baae4","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 1.03 seconds, 96.83 sentences/sec\n"]}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/finetuned_summary_model\").to('cuda')\n","tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/finetuned_summary_model\", do_lower_case=False, use_fast=False, keep_accents=True)\n","\n","def generate_heading(article):\n","    inputs = tokenizer(article, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to('cuda')\n","    output = model.generate(inputs[\"input_ids\"], max_length=100, num_beams=4, early_stopping=True)\n","    return tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","predictions = [generate_heading(article) for article in tqdm(batched_dataset[\"test\"][:100][\"Article\"])]\n","\n","metric_rouge = load_metric(\"rouge\")\n","references = batched_dataset[\"test\"][:100][\"Summary\"]\n","rouge_scores = metric_rouge.compute(predictions=predictions, references=references)\n","\n","P, R, F1 = score(predictions, references, lang='hi', verbose=True)\n","\n","with open(\"rouge_scores.txt\", \"w\") as f:\n","    f.write(str(rouge_scores))\n","\n","with open(\"bert_scsAaores.txt\", \"w\") as f:\n","    f.write(f\"P: {P.mean()}\\nR: {R.mean()}\\nF1: {F1.mean()}\")"]},{"cell_type":"code","execution_count":100,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T17:12:18.444387Z","iopub.status.busy":"2024-04-25T17:12:18.443266Z","iopub.status.idle":"2024-04-25T17:12:18.453490Z","shell.execute_reply":"2024-04-25T17:12:18.452293Z","shell.execute_reply.started":"2024-04-25T17:12:18.444349Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.7976) tensor(0.8187)\n"]}],"source":["print(P.mean(), R.mean())"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T16:25:37.705081Z","iopub.status.busy":"2024-04-25T16:25:37.703978Z","iopub.status.idle":"2024-04-25T16:25:37.715628Z","shell.execute_reply":"2024-04-25T16:25:37.714412Z","shell.execute_reply.started":"2024-04-25T16:25:37.705041Z"},"trusted":true},"outputs":[{"data":{"text/plain":["MBartDecoder(\n","  (embed_tokens): Embedding(64015, 1024, padding_idx=0)\n","  (embed_positions): MBartLearnedPositionalEmbedding(1026, 1024)\n","  (layers): ModuleList(\n","    (0-5): 6 x MBartDecoderLayer(\n","      (self_attn): MBartAttention(\n","        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","      )\n","      (activation_fn): GELUActivation()\n","      (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (encoder_attn): MBartAttention(\n","        (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","        (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n","      )\n","      (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n","      (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n","      (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    )\n","  )\n","  (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","  (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",")"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["model.get_decoder()"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T16:22:37.292345Z","iopub.status.busy":"2024-04-25T16:22:37.291445Z","iopub.status.idle":"2024-04-25T16:22:37.301112Z","shell.execute_reply":"2024-04-25T16:22:37.299748Z","shell.execute_reply.started":"2024-04-25T16:22:37.292309Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.2645527777777777, recall=0.1485628459453343, fmeasure=0.16433847644910538), mid=Score(precision=0.3513333333333334, recall=0.22113956893639553, fmeasure=0.23474194653030972), high=Score(precision=0.43181249999999993, recall=0.29594341199950713, fmeasure=0.30731551856296435)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.12899455266955268, recall=0.0689343135826592, fmeasure=0.07615594874681562), mid=Score(precision=0.1953225108225108, recall=0.12663205258793492, fmeasure=0.12961318622038434), high=Score(precision=0.269300505050505, recall=0.19312302713626245, fmeasure=0.189653580518209)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.26306944444444447, recall=0.15159578806556356, fmeasure=0.16513981259118302), mid=Score(precision=0.3453333333333333, recall=0.21982793367623082, fmeasure=0.23095734785995922), high=Score(precision=0.4323361111111112, recall=0.2971100534871046, fmeasure=0.3033035367246011)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.2617013888888889, recall=0.14981308020969397, fmeasure=0.16212930694130126), mid=Score(precision=0.34291666666666665, recall=0.21827507623095854, fmeasure=0.23181783177711296), high=Score(precision=0.42867222222222223, recall=0.29463708460656984, fmeasure=0.3031120801213302))}"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["rouge_scores"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","from transformers import AutoModelForSeq2SeqLM\n","\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super(CustomModel, self).__init__()\n","        self.seq2seq = AutoModelForSeq2SeqLM.from_pretrained('path_to_your_fine_tuned_model')\n","        self.similarity_attention = nn.Linear(self.seq2seq.config.hidden_size, 1)\n","\n","    def forward(self, input_ids, attention_mask, similarity_scores):\n","        # Pass the input through Seq2Seq model\n","        outputs = self.seq2seq(input_ids=input_ids, attention_mask=attention_mask)\n","        last_hidden_state = outputs.last_hidden_state\n","\n","        # Apply sentence similarity scores as attention\n","        similarity_attention_weights = torch.sigmoid(self.similarity_attention(similarity_scores))\n","        attended_output = last_hidden_state * similarity_attention_weights.unsqueeze(-1)\n","\n","        return attended_output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["!zip -r file.zip /kaggle/working/finetuned_summary_model\n","from IPython.display import FileLink\n","FileLink(r'file.zip')"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T16:51:51.508274Z","iopub.status.busy":"2024-04-25T16:51:51.507871Z","iopub.status.idle":"2024-04-25T16:51:51.516499Z","shell.execute_reply":"2024-04-25T16:51:51.515372Z","shell.execute_reply.started":"2024-04-25T16:51:51.508242Z"},"trusted":true},"outputs":[],"source":["def train_epoch(seq2seq_model , tokenizer, similarity_scores, train_dataset):\n","    for data in tqdm(train_dataset):\n","        article = data[\"Article\"]\n","        heading = data[\"Heading\"]\n","        summary = data[\"Summary\"]\n","        print(summary)\n","        break"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T16:51:57.780962Z","iopub.status.busy":"2024-04-25T16:51:57.780003Z","iopub.status.idle":"2024-04-25T16:51:57.898678Z","shell.execute_reply":"2024-04-25T16:51:57.887945Z","shell.execute_reply.started":"2024-04-25T16:51:57.780909Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2ed4fdbc0dc54620ac44e6ba0807633d","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/14857 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Kerala Minor Girl Rape Case - केरल के एर्नाकुलम जिले में 5 साल की बच्ची से रेप के बाद गला दबाकर हत्या कर दी गई। आरोपी ने बच्ची का शव बोरे में डालकर डंपिंग ग्राउंड में फेंक दिया\n"]}],"source":["similarity_scores = pkl.load(open(\"/kaggle/input/hindidataset/similarities.pkl\",'rb'))\n","train_epoch(seq2seq_model, tokenizer, similarity_scores, dataset[\"train\"])\n","    "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4862341,"sourceId":8218742,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
