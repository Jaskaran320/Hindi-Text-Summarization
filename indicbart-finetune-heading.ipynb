{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8217908,"sourceType":"datasetVersion","datasetId":4871196}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q rouge_score bert_score","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:21:44.736628Z","iopub.execute_input":"2024-04-24T17:21:44.737100Z","iopub.status.idle":"2024-04-24T17:22:00.383432Z","shell.execute_reply.started":"2024-04-24T17:21:44.737048Z","shell.execute_reply":"2024-04-24T17:22:00.382345Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments, TrainingArguments, pipeline\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom datasets import load_metric, Dataset\nfrom tqdm import tqdm\nfrom bert_score import score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-24T17:22:00.385713Z","iopub.execute_input":"2024-04-24T17:22:00.386111Z","iopub.status.idle":"2024-04-24T17:22:17.551497Z","shell.execute_reply.started":"2024-04-24T17:22:00.386058Z","shell.execute_reply":"2024-04-24T17:22:17.550746Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-24 17:22:08.710120: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-24 17:22:08.710248: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-24 17:22:08.849128: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicBART\", do_lower_case=False, use_fast=False, keep_accents=True)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(\"ai4bharat/IndicBART\").to('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:22:17.552640Z","iopub.execute_input":"2024-04-24T17:22:17.553405Z","iopub.status.idle":"2024-04-24T17:22:24.170634Z","shell.execute_reply.started":"2024-04-24T17:22:17.553361Z","shell.execute_reply":"2024-04-24T17:22:24.169768Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/498 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68ef22e64a974f85909b415d8acee484"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/832 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d35befc9aa1a47768fdb2495f9b8c51a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.90M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa326bd678c94084bb274a00e26164af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/221 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd1b843bbf80443298fdfff7b86290c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/398 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03fa23a700344fcf93929dad0a5c34ab"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/976M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5dfb1145076f4039a4b2f8db6c233ad4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/hindi-dataset/hindi_train.csv\")\ntrain_data.drop(columns=[\"Summary\"], inplace=True)\n\ntest_data = pd.read_csv(\"/kaggle/input/hindi-dataset/HindiNews_test.csv\")\ntest_data.rename(columns={\"id\": \"Id\"}, inplace=True)\ndata = pd.concat([train_data, test_data], axis=0)\n\ntrain_dataset, test_dataset = train_test_split(data, test_size=0.15, shuffle=False)\ntrain_dataset, val_dataset = train_test_split(train_dataset, test_size=0.1, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:26:43.379814Z","iopub.execute_input":"2024-04-24T17:26:43.380188Z","iopub.status.idle":"2024-04-24T17:26:46.094621Z","shell.execute_reply.started":"2024-04-24T17:26:43.380157Z","shell.execute_reply":"2024-04-24T17:26:46.093219Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(example):\n    inputs = tokenizer(example[\"Article\"], padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to('cuda')\n    outputs = tokenizer(example[\"Heading\"], padding=\"max_length\", truncation=True, max_length=64, return_tensors=\"pt\").to('cuda')\n    return {\"input_ids\": inputs[\"input_ids\"].tolist(), \"attention_mask\": inputs[\"attention_mask\"].tolist(), \"labels\": outputs[\"input_ids\"].tolist()}\n\ntrain_dataset = Dataset.from_pandas(train_dataset)\ntrain_dataset = train_dataset.map(preprocess_data, batched=True, batch_size=96)\nval_dataset = Dataset.from_pandas(val_dataset)\nval_dataset = val_dataset.map(preprocess_data, batched=True, batch_size=96)\ntest_dataset = Dataset.from_pandas(test_dataset)\ntest_dataset = test_dataset.map(preprocess_data, batched=True, batch_size=96)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:26:48.392464Z","iopub.execute_input":"2024-04-24T17:26:48.393217Z","iopub.status.idle":"2024-04-24T17:29:19.068751Z","shell.execute_reply.started":"2024-04-24T17:26:48.393180Z","shell.execute_reply":"2024-04-24T17:29:19.067682Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/18531 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d990622141154920aa973913e41433df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2060 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78645a2acab64a6aa7ff5976958a5688"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3634 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1580029b6add48bea3e1f1649eea4ec3"}},"metadata":{}}]},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"/kaggle/working/model\",\n    num_train_epochs=5,\n    logging_dir=\"/kaggle/working/logs\",\n    logging_steps=500,\n    overwrite_output_dir=True,\n    save_steps=1000,\n    eval_steps=500,\n    save_total_limit=3,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"/kaggle/working/finetuned_model\")\ntokenizer.save_pretrained(\"/kaggle/working/finetuned_model\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:29:53.097131Z","iopub.execute_input":"2024-04-24T17:29:53.098259Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7622' max='11585' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 7622/11585 1:06:24 < 34:32, 1.91 it/s, Epoch 3.29/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>2.484400</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.051800</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.956300</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.916400</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.884500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.857100</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.857500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.843700</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.831800</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.806700</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.803800</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.798400</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.799700</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.795700</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.779200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'forced_eos_token_id': 2}\n","output_type":"stream"}]},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/finetuned_model\").to('cuda')\ntokenizer = AutoTokenizer.from_pretrained(\"/kaggle/working/finetuned_model\", do_lower_case=False, use_fast=False, keep_accents=True)\n\ndef generate_heading(article):\n    inputs = tokenizer(article, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\").to('cuda')\n    output = model.generate(inputs[\"input_ids\"], max_length=64, num_beams=4, early_stopping=True)\n    return tokenizer.decode(output[0], skip_special_tokens=True)\n\npredictions = [generate_heading(article) for article in test_dataset[\"Article\"]]\n\nmetric_rouge = load_metric(\"rouge\")\nreferences = test_dataset[\"Heading\"]\nrouge_scores = metric_rouge.compute(predictions=predictions, references=references)\n\nP, R, F1 = score(predictions, references, lang='hi', verbose=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:26:20.612336Z","iopub.status.idle":"2024-04-24T17:26:20.612688Z","shell.execute_reply.started":"2024-04-24T17:26:20.612518Z","shell.execute_reply":"2024-04-24T17:26:20.612533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"rouge_scores.txt\", \"w\") as f:\n    f.write(str(rouge_scores))\n\nwith open(\"bert_scores.txt\", \"w\") as f:\n    f.write(f\"P: {P.mean()}\\nR: {R.mean()}\\nF1: {F1.mean()}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:26:20.614500Z","iopub.status.idle":"2024-04-24T17:26:20.614957Z","shell.execute_reply.started":"2024-04-24T17:26:20.614715Z","shell.execute_reply":"2024-04-24T17:26:20.614734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(rouge_scores)","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:26:20.617127Z","iopub.status.idle":"2024-04-24T17:26:20.617550Z","shell.execute_reply.started":"2024-04-24T17:26:20.617329Z","shell.execute_reply":"2024-04-24T17:26:20.617347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(F1.mean())","metadata":{"execution":{"iopub.status.busy":"2024-04-24T17:26:20.618588Z","iopub.status.idle":"2024-04-24T17:26:20.618995Z","shell.execute_reply.started":"2024-04-24T17:26:20.618802Z","shell.execute_reply":"2024-04-24T17:26:20.618821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}