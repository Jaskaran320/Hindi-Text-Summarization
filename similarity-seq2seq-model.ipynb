{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -q rouge_score bert_score\n","!pip install evaluate"]},{"cell_type":"code","execution_count":12,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-25T18:22:50.650587Z","iopub.status.busy":"2024-04-25T18:22:50.650178Z","iopub.status.idle":"2024-04-25T18:22:50.668284Z","shell.execute_reply":"2024-04-25T18:22:50.667290Z","shell.execute_reply.started":"2024-04-25T18:22:50.650556Z"},"trusted":true},"outputs":[],"source":["from transformers import MBartForConditionalGeneration, AutoModelForSeq2SeqLM\n","from transformers import AlbertTokenizer, AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","import pickle as pkl\n","import pandas as pd\n","import numpy as np\n","from datasets import Dataset\n","import torch\n","from transformers import DataCollatorForSeq2Seq\n","from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from tqdm.notebook import tqdm\n","from datasets import load_metric\n","import wandb"]},{"cell_type":"markdown","metadata":{},"source":["# Custom Dataset"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T18:22:53.207197Z","iopub.status.busy":"2024-04-25T18:22:53.206606Z","iopub.status.idle":"2024-04-25T18:22:53.213157Z","shell.execute_reply":"2024-04-25T18:22:53.212119Z","shell.execute_reply.started":"2024-04-25T18:22:53.207158Z"},"trusted":true},"outputs":[],"source":["class MyDataset(torch.utils.data.Dataset):\n","    def __init__(self, dataframe):\n","        self.df = dataframe\n","    \n","    def __getlen__(self):\n","        return len(self.dataframe)\n","    \n","    def __getitem(self, index):\n","        return self.dataframe.iloc[index]"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T18:23:11.870360Z","iopub.status.busy":"2024-04-25T18:23:11.869484Z","iopub.status.idle":"2024-04-25T18:23:14.693247Z","shell.execute_reply":"2024-04-25T18:23:14.692350Z","shell.execute_reply.started":"2024-04-25T18:23:11.870323Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"/kaggle/input/hindidataset/HindiNews/HindiNews_train_v2/hindi_train.csv\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T18:23:14.695863Z","iopub.status.busy":"2024-04-25T18:23:14.695189Z","iopub.status.idle":"2024-04-25T18:23:14.713501Z","shell.execute_reply":"2024-04-25T18:23:14.712540Z","shell.execute_reply.started":"2024-04-25T18:23:14.695826Z"},"trusted":true},"outputs":[],"source":["df_train, df_test = train_test_split(df, test_size=0.3, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-25T18:23:16.104447Z","iopub.status.busy":"2024-04-25T18:23:16.104057Z"},"trusted":true},"outputs":[],"source":["df_train = pd.read_csv(\"/kaggle/input/hindidataset/HindiNews/HindiNews_train_v2/hindi_train.csv\")\n","df_test = pd.read_csv(\"/kaggle/input/hindidataset/HindiNews/HindiNews_test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_dataset = MyDataset(df_train)\n","test_dataset = MyDataset(df_test)"]},{"cell_type":"markdown","metadata":{},"source":["# Similarity Seq2Seq Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","from transformers import AutoModelForSeq2SeqLM\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, model_path):\n","        super(CustomModel, self).__init__()\n","        self.seq2seq = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n","        self.similarity_attention = nn.Linear(self.seq2seq.config.hidden_size, 1)\n","\n","    def forward(self, input_ids, attention_mask, similarity_scores):\n","        outputs = self.seq2seq(input_ids=input_ids, attention_mask=attention_mask)\n","        last_hidden_state = outputs.last_hidden_state\n","        \n","        sentences = input_ids.masked_fill(input_ids == 0, 843).split(843, dim=1)\n","        num_sentences = len(sentences)\n","        \n","        similarity_attention_weights = torch.sigmoid(self.similarity_attention(last_hidden_state))\n","        \n","        attended_outputs = []\n","        for i in range(num_sentences):\n","            sentence = sentences[i]\n","            sentence_length = torch.sum(sentence != 0).item()\n","            sentence_similarity_scores = similarity_scores[i, :sentence_length].unsqueeze(-1)\n","            sentence_attention_weights = similarity_attention_weights[i, :sentence_length]\n","            sentence_attended_output = sentence_attention_weights * last_hidden_state[i, :sentence_length]\n","            attended_outputs.append(sentence_attended_output)\n","        \n","        attended_output = torch.cat(attended_outputs, dim=0)\n","        \n","        return attended_output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import AdamW\n","\n","\n","model = CustomModel()\n","model = model.to('cuda')  \n","\n","\n","optimizer = AdamW(model.parameters(), lr=1e-5)\n","num_epochs = 10\n","dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n","\n","def compute_loss(outputs, labels):\n","    return torch.nn.functional.mse_loss(outputs, labels)\n","\n","\n","for epoch in range(num_epochs):\n","    for batch in dataloader:\n","\n","        input_ids, attention_mask, similarity_scores, labels = batch\n","        input_ids = input_ids.to('cuda')\n","        attention_mask = attention_mask.to('cuda')\n","        similarity_scores = similarity_scores.to('cuda')\n","        labels = labels.to('cuda')\n","\n","\n","        outputs = model(input_ids=input_ids, attention_mask=attention_mask, similarity_scores=similarity_scores)\n","\n","        loss = compute_loss(outputs, labels)\n","\n","    \n","        loss.backward()\n","\n","        optimizer.step()\n","        optimizer.zero_grad()\n","\n","    print(f'Epoch {epoch+1} completed')\n"]},{"cell_type":"markdown","metadata":{},"source":["# Testing on samples (Sanity Check)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torch import nn\n","from transformers import AutoModelForSeq2SeqLM\n","\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super(CustomModel, self).__init__()\n","        self.seq2seq = AutoModelForSeq2SeqLM.from_pretrained('/kaggle/working/finetuned_model')\n","        self.similarity_attention = nn.Linear(self.seq2seq.config.hidden_size, 1)\n","\n","    def forward(self, input_ids, attention_mask, similarity_scores):\n","        outputs = self.seq2seq(input_ids=input_ids, attention_mask=attention_mask)\n","        last_hidden_state = outputs.last_hidden_state\n","\n","        similarity_attention_weights = torch.sigmoid(self.similarity_attention(similarity_scores))\n","        attended_output = last_hidden_state * similarity_attention_weights.unsqueeze(-1)\n","\n","        return attended_output"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!zip -r file.zip /kaggle/working/finetuned_summary_model\n","from IPython.display import FileLink\n","FileLink(r'file.zip')"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4862341,"sourceId":8218742,"sourceType":"datasetVersion"}],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.11"}},"nbformat":4,"nbformat_minor":4}
